# 分类

## How
线性模型
- 线性回归
- 岭分类
- 逻辑斯蒂回归
- 线性判别分析
- 线性支持向量机

基扩展
- 三次方样条
- 自然三次方样条
- 广义可加模型
- 多元自适应样条

核方法
- 稀疏向量机
支持向量机

原型方法
- K近邻
K均值分类
高斯混合模型
二次判别分析
灵活判别分析
混合判别分析

自适应基扩展
- 决策树
投票法
装袋法
多余树
随机森林
提升法
自适应提升
梯度提升机
基于直方图的梯度提升
极端梯度提升
轻量梯度提升机
堆叠法
神经网络

概率方法
- 朴素贝叶斯
贝叶斯高斯混合模型
高斯过程

自动机器学习


## 实验结论
这个实验在混合数据集上调查了7类共34个模型。假设我们知道数据的生成过程，采用混合判别分析能够很好地捕捉到数据的结构，其所得到的误差率已经很接近最优贝叶斯分类器了。但在实际中我们不知道数据的生成过程，从三种调参方法的对比结果可以看出，总体而言，由逻辑斯蒂回归，K邻近决策树和支持向量机组合而成的软投票法表现最好，而在TPE采样器中，支持向量机表现最好，它们的结果也超过了最优贝叶斯分类器的误差率。在前三名中，投票法占据两席，这说明对于这个简单数据集，在特征不是很丰富的情况下，多样的基本学习模型能捕捉能从各个侧面捕捉数据集的结构。另外，从整体排名来看，自适应基扩展与核方法两类模型排名靠前。当然，由于一些随机性，这些排名并不固定，并且我们也不能仅根据一个数据集来详细评价各个模型的好坏。")
## 未来计划
1. 给出贝叶斯参数优化更多解释
2. 添加更多的分类器，尤其概率分类模型。
3. 从头编写每个模型算法，并上传至[Github](https://github.com/TaiChiTiger/machine-learning-algorithms)
